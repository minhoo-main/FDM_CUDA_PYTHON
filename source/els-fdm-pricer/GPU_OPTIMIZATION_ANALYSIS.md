# GPU ìµœì í™” í˜„í™© ë° ê°œì„  ë°©ì•ˆ

## í˜„ì¬ GPU ì ìš© ìƒíƒœ (âœ… = GPU, âŒ = CPU)

### 1. ë°ì´í„° ì €ì¥ ìœ„ì¹˜

#### âœ… GPU ë©”ëª¨ë¦¬ì— ì €ì¥ë˜ëŠ” ë°ì´í„°
**ìœ„ì¹˜**: `gpu_adi_solver.py:57-108`

```python
# ADI ê³„ìˆ˜ë“¤ (ë¯¸ë¦¬ ê³„ì‚° í›„ GPUì— ìƒì£¼)
self.alpha1_gpu = xp.zeros(N1 - 1)  # S1 ë°©í–¥ lower diagonal
self.beta1_gpu = xp.zeros(N1)       # S1 ë°©í–¥ main diagonal
self.gamma1_gpu = xp.zeros(N1 - 1)  # S1 ë°©í–¥ upper diagonal

self.alpha2_gpu = xp.zeros(N2 - 1)  # S2 ë°©í–¥ lower diagonal
self.beta2_gpu = xp.zeros(N2)       # S2 ë°©í–¥ main diagonal
self.gamma2_gpu = xp.zeros(N2 - 1)  # S2 ë°©í–¥ upper diagonal

# ê³µê°„ ê·¸ë¦¬ë“œ (GPUì— ìƒì£¼)
self.S1_mesh_gpu = xp.array(self.grid.S1_mesh)  # (N1 Ã— N2)
self.S2_mesh_gpu = xp.array(self.grid.S2_mesh)  # (N1 Ã— N2)

# ê°€ê²© ê·¸ë¦¬ë“œ (ê³„ì‚° ì¤‘ GPUì— ìƒì£¼)
V = xp.array(V_T)  # (N1 Ã— N2)
```

**íš¨ê³¼:**
- CPUâ†”GPU ë°ì´í„° ì „ì†¡ ìµœì†Œí™”
- ì‹œê°„ ë£¨í”„ ë™ì•ˆ GPUì—ì„œë§Œ ê³„ì‚°
- ë©”ëª¨ë¦¬ ëŒ€ì—­í­ í™œìš©

---

### 2. ê³„ì‚° ê³¼ì • ë¶„ì„

#### âœ… GPUì—ì„œ ì‹¤í–‰ë˜ëŠ” ì—°ì‚°

**A. ê²½ê³„ ì¡°ê±´ ì ìš©** (`gpu_adi_solver.py:235-248`)
```python
def _apply_boundary_conditions_gpu(self, V):
    xp = self.xp  # cupy
    V_new = V.copy()

    # Vectorized ì—°ì‚° (GPUì—ì„œ ë³‘ë ¬ ì‹¤í–‰)
    V_new[0, :] = 0.0                              # í•œ ë²ˆì— N2ê°œ ê°’ ì„¤ì •
    V_new[:, 0] = 0.0                              # í•œ ë²ˆì— N1ê°œ ê°’ ì„¤ì •
    V_new[-1, :] = 2 * V_new[-2, :] - V_new[-3, :] # GPUì—ì„œ ë²¡í„° ì—°ì‚°
    V_new[:, -1] = 2 * V_new[:, -2] - V_new[:, -3] # GPUì—ì„œ ë²¡í„° ì—°ì‚°

    return V_new
```

**íš¨ê³¼:** âœ… ì™„ë²½í•œ GPU í™œìš© (vectorized)

**B. Thomas ì•Œê³ ë¦¬ì¦˜ ë‚´ë¶€ ì—°ì‚°** (`gpu_adi_solver.py:202-233`)
```python
def _solve_tridiagonal_gpu(self, lower, diag, upper, rhs):
    xp = self.xp  # cupy

    # ë©”ëª¨ë¦¬ í• ë‹¹ (GPU)
    c_prime = xp.zeros(N - 1)
    d_prime = xp.zeros(N)
    x = xp.zeros(N)

    # Forward sweep (GPUì—ì„œ ì‹¤í–‰ë˜ì§€ë§Œ ìˆœì°¨ì !)
    c_prime[0] = upper[0] / diag[0]  # GPU scalar op
    d_prime[0] = rhs[0] / diag[0]    # GPU scalar op

    for i in range(1, N - 1):  # âš ï¸ Python for loop
        denom = diag[i] - lower[i - 1] * c_prime[i - 1]
        c_prime[i] = upper[i] / denom
        d_prime[i] = (rhs[i] - lower[i - 1] * d_prime[i - 1]) / denom

    # Backward substitution (GPUì—ì„œ ì‹¤í–‰ë˜ì§€ë§Œ ìˆœì°¨ì !)
    for i in range(N - 2, -1, -1):  # âš ï¸ Python for loop
        x[i] = d_prime[i] - c_prime[i] * x[i + 1]
```

**íš¨ê³¼:** â–³ GPUì—ì„œ ì‹¤í–‰ë˜ì§€ë§Œ ìˆœì°¨ì 
- ê° ì—°ì‚°ì€ GPUì—ì„œ ì‹¤í–‰ (ë¹ ë¥¸ ë©”ëª¨ë¦¬ ì ‘ê·¼)
- Python for loopë¡œ ìˆœì°¨ ì‹¤í–‰ (ë³‘ë ¬í™” ì•ˆ ë¨)
- ë°ì´í„° ì˜ì¡´ì„± ë•Œë¬¸ì— ì–´ì©” ìˆ˜ ì—†ìŒ

**C. S1/S2 ë°©í–¥ í’€ê¸°** (`gpu_adi_solver.py:156-200`)
```python
def _solve_S1_direction_gpu(self, V):
    N1, N2 = self.N1, self.N2
    V_new = xp.zeros_like(V)  # GPU ë©”ëª¨ë¦¬

    # âš ï¸ ë¬¸ì œ: ìˆœì°¨ì  for loop
    for j in range(N2):  # 100ê°œ ì‹œìŠ¤í…œì„ í•˜ë‚˜ì”©
        rhs = V[:, j].copy()
        rhs[0] = 0.0
        rhs[-1] = V[-1, j]

        # ê° ì‹œìŠ¤í…œì„ ìˆœì°¨ì ìœ¼ë¡œ í’€ê¸°
        V_new[:, j] = self._solve_tridiagonal_gpu(...)

    return V_new
```

**íš¨ê³¼:** â–³ ë¶€ë¶„ì  GPU í™œìš©
- ê° tridiagonal solveëŠ” GPUì—ì„œ ì‹¤í–‰
- í•˜ì§€ë§Œ N2ê°œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
- **ë³‘ë ¬í™” ì•ˆ ë¨**

#### âŒ CPUì—ì„œ ì‹¤í–‰ë˜ëŠ” ì—°ì‚°

**A. ë§Œê¸° í˜ì´ì˜¤í”„ ì´ˆê¸°í™”** (`gpu_els_pricer.py:92-118`)
```python
def _initialize_terminal_payoff(self) -> np.ndarray:
    N1, N2 = self.grid.N1, self.grid.N2
    V_T = np.zeros((N1, N2))  # âŒ NumPy (CPU)

    # âŒ ì¤‘ì²© for loop (CPUì—ì„œ ìˆœì°¨ ì‹¤í–‰)
    for i in range(N1):      # 100ë²ˆ
        for j in range(N2):  # 100ë²ˆ â†’ ì´ 10,000ë²ˆ ë°˜ë³µ
            S1 = S1_mesh[i, j]
            S2 = S2_mesh[i, j]

            # ELS payoff ê³„ì‚° (ë³µì¡í•œ ì¡°ê±´ë¬¸)
            is_redeemed, payoff = self.product.check_early_redemption(...)
            if is_redeemed:
                V_T[i, j] = payoff
            else:
                ki_occurred = self.product.check_knock_in(...)
                V_T[i, j] = self.product.payoff_at_maturity(...)
```

**íš¨ê³¼:** âŒ ì™„ì „íˆ CPUì—ì„œ ìˆœì°¨ ì‹¤í–‰
- 10,000ë²ˆ ë°˜ë³µ (100Ã—100 ê·¸ë¦¬ë“œ)
- ê° ë°˜ë³µì—ì„œ ì¡°ê±´ë¬¸ ì²´í¬
- **GPU ì™„ì „íˆ ë¯¸ì‚¬ìš©**

**B. ì¡°ê¸°ìƒí™˜ ì½œë°±** (`gpu_els_pricer.py:120-138`)
```python
def _early_redemption_callback(self, V, S1_mesh, S2_mesh, obs_idx):
    V_adjusted = V.copy()  # âŒ NumPy (CPU)
    N1, N2 = V.shape

    # âŒ ì¤‘ì²© for loop (CPUì—ì„œ ìˆœì°¨ ì‹¤í–‰)
    for i in range(N1):      # 100ë²ˆ
        for j in range(N2):  # 100ë²ˆ â†’ ì´ 10,000ë²ˆ ë°˜ë³µ
            S1 = S1_mesh[i, j]
            S2 = S2_mesh[i, j]

            is_redeemed, payoff = self.product.check_early_redemption(...)
            if is_redeemed:
                V_adjusted[i, j] = payoff
```

**íš¨ê³¼:** âŒ ì™„ì „íˆ CPUì—ì„œ ìˆœì°¨ ì‹¤í–‰
- ê° ê´€ì°°ì¼ë§ˆë‹¤ 10,000ë²ˆ ë°˜ë³µ
- 6ê°œ ê´€ì°°ì¼ â†’ 60,000ë²ˆ ë°˜ë³µ
- **ë§¤ë²ˆ GPUâ†”CPU ë°ì´í„° ì „ì†¡ ë°œìƒ**

**C. GPUâ†”CPU ì „ì†¡** (`gpu_adi_solver.py:139-148`)
```python
# ì¡°ê¸°ìƒí™˜ ì²´í¬ ì‹œ
if early_exercise_callback is not None:
    # GPU â†’ CPU (ëŠë¦¼!)
    V_cpu = cp.asnumpy(V)
    S1_mesh_cpu = cp.asnumpy(self.S1_mesh_gpu)
    S2_mesh_cpu = cp.asnumpy(self.S2_mesh_gpu)

    # CPUì—ì„œ ì½œë°± ì‹¤í–‰
    V_cpu = early_exercise_callback(V_cpu, S1_mesh_cpu, S2_mesh_cpu, n, t)

    # CPU â†’ GPU (ëŠë¦¼!)
    V = xp.array(V_cpu)
```

**íš¨ê³¼:** âŒ ë°ì´í„° ì „ì†¡ ì˜¤ë²„í—¤ë“œ
- ê° ê´€ì°°ì¼ë§ˆë‹¤ ì „ì†¡ (6íšŒ)
- 100Ã—100 ê·¸ë¦¬ë“œ: ì•½ 80KB ì „ì†¡
- PCIe ëŒ€ì—­í­: 16GB/s â†’ ì „ì†¡ ì‹œê°„ ë¯¸ë¯¸í•˜ì§€ë§Œ ë¶ˆí•„ìš”

---

## ì„±ëŠ¥ ë³‘ëª© ë¶„ì„

### ì‹œê°„ ì†Œë¹„ ë¶„í¬ (100Ã—100 ê·¸ë¦¬ë“œ, 200 time steps ê¸°ì¤€)

```
ì´ ì‹¤í–‰ ì‹œê°„: 0.5ì´ˆ (í˜„ì¬ GPU êµ¬í˜„)

1. ë§Œê¸° í˜ì´ì˜¤í”„ ì´ˆê¸°í™”        : ~0.01s (2%)   âŒ CPU
2. ADI ì‹œê°„ ë£¨í”„ (200íšŒ)       : ~0.44s (88%)  â–³ ë¶€ë¶„ GPU
   â”œâ”€ S1 ë°©í–¥ solve (100íšŒ)    : ~0.20s        â–³ GPU (ìˆœì°¨)
   â”œâ”€ S2 ë°©í–¥ solve (100íšŒ)    : ~0.20s        â–³ GPU (ìˆœì°¨)
   â””â”€ ê²½ê³„ì¡°ê±´                  : ~0.04s        âœ… GPU (ì™„ë²½)
3. ì¡°ê¸°ìƒí™˜ ì½œë°± (6íšŒ)         : ~0.05s (10%)  âŒ CPU
   â”œâ”€ GPUâ†’CPU ì „ì†¡             : ~0.001s
   â”œâ”€ CPU ê³„ì‚° (10,000ë²ˆ)      : ~0.048s
   â””â”€ CPUâ†’GPU ì „ì†¡             : ~0.001s

ë³‘ëª©:
1ìœ„. ADI solve (88%) - ìˆœì°¨ì  for loop
2ìœ„. ì¡°ê¸°ìƒí™˜ ì½œë°± (10%) - CPU ì¤‘ì²© loop
3ìœ„. ë‚˜ë¨¸ì§€ (2%)
```

---

## ê°œì„  ê°€ëŠ¥í•œ ë¶€ë¶„

### ğŸ¯ ìš°ì„ ìˆœìœ„ 1: Batched Tridiagonal Solver (ìµœëŒ€ íš¨ê³¼)

**í˜„ì¬ ë¬¸ì œ:**
```python
# 100ê°œ ì‹œìŠ¤í…œì„ í•˜ë‚˜ì”©
for j in range(N2):  # 100ë²ˆ ìˆœì°¨
    V_new[:, j] = solve_tridiagonal(...)
```

**ê°œì„ ì•ˆ: cuSPARSE ì‚¬ìš©**
```python
# CuPy wrapper for cuSPARSE
from cupyx.scipy.sparse.linalg import gtsv

def _solve_S1_direction_gpu_batched(self, V):
    # ëª¨ë“  RHSë¥¼ í•˜ë‚˜ì˜ í–‰ë ¬ë¡œ
    # shape: (N1, N2) - N2ê°œì˜ tridiagonal systems

    # Batched solve (í•œ ë²ˆì— N2ê°œ ì‹œìŠ¤í…œ!)
    V_new = solve_batched_tridiagonal(
        self.alpha1_gpu,  # lower
        self.beta1_gpu,   # diag
        self.gamma1_gpu,  # upper
        V                 # N2ê°œì˜ RHS
    )

    return V_new
```

**ì˜ˆìƒ íš¨ê³¼:**
- í˜„ì¬: 100ê°œ Ã— 0.002s = 0.2s
- ê°œì„ : 1íšŒ Ã— 0.01s = 0.01s
- **20ë°° í–¥ìƒ**

**êµ¬í˜„ ë‚œì´ë„:** â­â­â˜†â˜†â˜† (ë³´í†µ)
**ì‘ì—… ì‹œê°„:** 1-2ì¼

---

### ğŸ¯ ìš°ì„ ìˆœìœ„ 2: GPU Vectorized ì¡°ê¸°ìƒí™˜ ì²´í¬

**í˜„ì¬ ë¬¸ì œ:**
```python
# CPU ì¤‘ì²© loop (10,000ë²ˆ ë°˜ë³µ)
for i in range(N1):
    for j in range(N2):
        S1 = S1_mesh[i, j]
        S2 = S2_mesh[i, j]
        is_redeemed, payoff = check_early_redemption(S1, S2, obs_idx)
        if is_redeemed:
            V_adjusted[i, j] = payoff
```

**ê°œì„ ì•ˆ: GPU Vectorized**
```python
def _early_redemption_callback_gpu(self, V, obs_idx):
    xp = self.xp

    # ëª¨ë“  ê²©ìì ì—ì„œ worst-of ê³„ì‚° (vectorized)
    perf1 = self.S1_mesh_gpu / self.product.S1_0  # (N1Ã—N2)
    perf2 = self.S2_mesh_gpu / self.product.S2_0  # (N1Ã—N2)

    if self.product.worst_of:
        worst_perf = xp.minimum(perf1, perf2)  # GPUì—ì„œ ë³‘ë ¬
    else:
        worst_perf = xp.maximum(perf1, perf2)

    # ì¡°ê¸°ìƒí™˜ ì¡°ê±´ ì²´í¬ (vectorized)
    barrier = self.product.redemption_barriers[obs_idx]
    is_redeemed = worst_perf >= barrier  # (N1Ã—N2) boolean array

    # ì¡°ê¸°ìƒí™˜ í˜ì´ì˜¤í”„ (vectorized)
    coupon = self.product.coupons[obs_idx]
    redemption_value = self.product.principal + coupon

    # ì¡°ê±´ë¶€ ì—…ë°ì´íŠ¸ (GPUì—ì„œ ë³‘ë ¬)
    V_new = xp.where(is_redeemed, redemption_value, V)

    return V_new
```

**ì˜ˆìƒ íš¨ê³¼:**
- í˜„ì¬: 0.048s (10,000ë²ˆ ë£¨í”„)
- ê°œì„ : 0.001s (vectorized)
- **50ë°° í–¥ìƒ**

**êµ¬í˜„ ë‚œì´ë„:** â­â­â­â˜†â˜† (ì¤‘ê°„)
**ì‘ì—… ì‹œê°„:** 2-3ì¼
**ì£¼ì˜:** KI ì²´í¬ ë¡œì§ë„ vectorize í•„ìš”

---

### ğŸ¯ ìš°ì„ ìˆœìœ„ 3: GPU Vectorized ë§Œê¸° í˜ì´ì˜¤í”„

**í˜„ì¬ ë¬¸ì œ:**
```python
# CPU ì¤‘ì²© loop (10,000ë²ˆ)
for i in range(N1):
    for j in range(N2):
        V_T[i, j] = calculate_payoff(S1_mesh[i,j], S2_mesh[i,j])
```

**ê°œì„ ì•ˆ:**
```python
def _initialize_terminal_payoff_gpu(self):
    xp = self.xp

    # GPU ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ê³„ì‚°
    S1_mesh_gpu = xp.array(self.grid.S1_mesh)
    S2_mesh_gpu = xp.array(self.grid.S2_mesh)

    # Worst-of ê³„ì‚° (vectorized)
    perf1 = S1_mesh_gpu / self.product.S1_0
    perf2 = S2_mesh_gpu / self.product.S2_0
    worst_perf = xp.minimum(perf1, perf2)

    # ë§Œê¸° í˜ì´ì˜¤í”„ (vectorized)
    last_obs_idx = len(self.product.observation_dates) - 1
    barrier = self.product.redemption_barriers[last_obs_idx]
    coupon = self.product.coupons[last_obs_idx]

    # ì¡°ê¸°ìƒí™˜ ì²´í¬
    is_redeemed = worst_perf >= barrier
    V_redeemed = self.product.principal + coupon

    # Knock-In ì²´í¬ (vectorized)
    ki_barrier = self.product.ki_barrier
    ki_occurred = (worst_perf < ki_barrier)

    # ì¡°ê±´ë¶€ í˜ì´ì˜¤í”„
    V_ki = self.product.principal * xp.minimum(1.0, worst_perf)
    V_no_ki = self.product.principal + coupon

    # ìµœì¢… í˜ì´ì˜¤í”„ (nested where)
    V_T = xp.where(
        is_redeemed,
        V_redeemed,
        xp.where(ki_occurred, V_ki, V_no_ki)
    )

    return V_T
```

**ì˜ˆìƒ íš¨ê³¼:**
- í˜„ì¬: 0.01s
- ê°œì„ : 0.001s
- **10ë°° í–¥ìƒ** (ë¹„ì¤‘ì´ ì‘ì•„ ì „ì²´ ì˜í–¥ì€ ë¯¸ë¯¸)

**êµ¬í˜„ ë‚œì´ë„:** â­â­â˜†â˜†â˜† (ì‰¬ì›€)
**ì‘ì—… ì‹œê°„:** 1ì¼

---

### ğŸ¯ ìš°ì„ ìˆœìœ„ 4: Parallel Cyclic Reduction (ê³ ê¸‰)

**í˜„ì¬ Thomas ì•Œê³ ë¦¬ì¦˜:**
```python
# Forward sweep (ìˆœì°¨ì , O(N))
for i in range(1, N-1):
    c_prime[i] = upper[i] / (diag[i] - lower[i-1] * c_prime[i-1])
    d_prime[i] = (rhs[i] - lower[i-1] * d_prime[i-1]) / (diag[i] - ...)

# Backward substitution (ìˆœì°¨ì , O(N))
for i in range(N-2, -1, -1):
    x[i] = d_prime[i] - c_prime[i] * x[i+1]
```

**Cyclic Reduction (ë³‘ë ¬, O(log N)):**
```python
# Reduction phase (log N steps, ê° stepì€ ë³‘ë ¬)
for level in range(log2(N)):
    # ëª¨ë“  ì§ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ë³‘ë ¬ë¡œ ì œê±°
    parallel_eliminate_even_indices()

# Back-substitution phase (log N steps, ê° stepì€ ë³‘ë ¬)
for level in range(log2(N)):
    # ì œê±°í–ˆë˜ ì ë“¤ì„ ë³‘ë ¬ë¡œ ë³µì›
    parallel_restore_eliminated_points()
```

**ì˜ˆìƒ íš¨ê³¼:**
- ê° tridiagonal solve: O(N) â†’ O(log N)
- 100 í¬ì¸íŠ¸: ìˆœì°¨ 100 ops â†’ ë³‘ë ¬ 7 steps
- **ì´ë¡ ì  15ë°° í–¥ìƒ**
- **ì‹¤ì œë¡œëŠ” 3-5ë°°** (GPU launch overhead)

**êµ¬í˜„ ë‚œì´ë„:** â­â­â­â­â­ (ë§¤ìš° ì–´ë ¤ì›€)
**ì‘ì—… ì‹œê°„:** 2-3ì£¼
**ì£¼ì˜:** ìˆ˜ì¹˜ ì•ˆì •ì„± ë¬¸ì œ ê°€ëŠ¥

---

## ì¢…í•© ê°œì„  ë¡œë“œë§µ

### Phase 1: Quick Wins (1ì£¼)

**1-1. Batched Tridiagonal Solver**
- cuSPARSE ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©
- ì˜ˆìƒ í–¥ìƒ: 20ë°° (ì „ì²´ì˜ 88%)
- **ì „ì²´ ì†ë„: 0.5s â†’ 0.05s (10ë°° í–¥ìƒ)**

**1-2. Vectorized ì¡°ê¸°ìƒí™˜ ì²´í¬**
- CuPy vectorized ì—°ì‚°
- ì˜ˆìƒ í–¥ìƒ: 50ë°° (ì „ì²´ì˜ 10%)
- **ì „ì²´ ì†ë„: 0.05s â†’ 0.04s (1.25ë°° í–¥ìƒ)**

**1-3. Vectorized ë§Œê¸° í˜ì´ì˜¤í”„**
- CuPy vectorized ì—°ì‚°
- ì˜ˆìƒ í–¥ìƒ: 10ë°° (ì „ì²´ì˜ 2%)
- **ì „ì²´ ì†ë„: 0.04s â†’ 0.04s (ë¯¸ë¯¸í•œ í–¥ìƒ)**

**Phase 1 ì´ ì˜ˆìƒ í–¥ìƒ: 12-15ë°°**
**ìµœì¢… ì†ë„: 0.5s â†’ 0.03-0.04s**

---

### Phase 2: Advanced Optimization (2-3ì£¼)

**2-1. Custom CUDA Kernel for Batched Thomas**
```cuda
__global__ void batched_thomas_kernel(
    const float* __restrict__ lower,
    const float* __restrict__ diag,
    const float* __restrict__ upper,
    const float* __restrict__ rhs,
    float* __restrict__ solution,
    int N, int batch_size
) {
    int batch_id = blockIdx.x * blockDim.x + threadIdx.x;
    if (batch_id >= batch_size) return;

    // Shared memory for this batch
    extern __shared__ float shared[];
    float* c_prime = shared;
    float* d_prime = &shared[N];

    // Forward sweep
    c_prime[0] = upper[0] / diag[0];
    d_prime[0] = rhs[batch_id * N] / diag[0];

    for (int i = 1; i < N-1; i++) {
        float denom = diag[i] - lower[i-1] * c_prime[i-1];
        c_prime[i] = upper[i] / denom;
        d_prime[i] = (rhs[batch_id*N + i] - lower[i-1]*d_prime[i-1]) / denom;
    }

    // Backward substitution
    solution[batch_id*N + N-1] = d_prime[N-1];
    for (int i = N-2; i >= 0; i--) {
        solution[batch_id*N + i] = d_prime[i] - c_prime[i]*solution[batch_id*N + i+1];
    }
}
```

**ì˜ˆìƒ íš¨ê³¼:** ì¶”ê°€ 2-3ë°° í–¥ìƒ

**2-2. Parallel Cyclic Reduction**
- ê° Thomas solveë¥¼ O(log N)ìœ¼ë¡œ
- ì˜ˆìƒ íš¨ê³¼: ì¶”ê°€ 3-5ë°° í–¥ìƒ

**Phase 2 ì´ ì˜ˆìƒ í–¥ìƒ: Phase 1 ëŒ€ë¹„ 5-10ë°°**
**ìµœì¢… ì†ë„: 0.03s â†’ 0.003-0.006s**

---

### Phase 3: Memory Optimization (1ì£¼)

**3-1. Pinned Memory**
```python
# CPUâ†”GPU ì „ì†¡ ì†ë„ í–¥ìƒ
V_T_pinned = cp.cuda.alloc_pinned_memory(V_T.nbytes)
np.copyto(V_T_pinned, V_T)
V_T_gpu = cp.asarray(V_T_pinned)
```

**3-2. Stream Overlap**
```python
# ê³„ì‚°ê³¼ ì „ì†¡ ë™ì‹œ ì§„í–‰
stream1 = cp.cuda.Stream()
stream2 = cp.cuda.Stream()

with stream1:
    solve_S1_direction()
with stream2:
    transfer_data()
```

**ì˜ˆìƒ íš¨ê³¼:** ì¶”ê°€ 10-20% í–¥ìƒ

---

## ìµœì¢… ì„±ëŠ¥ ì˜ˆì¸¡

### í˜„ì¬ (Baseline)
```
100Ã—100 ê·¸ë¦¬ë“œ, 200 time steps
GPU (í˜„ì¬): 0.5ì´ˆ
CPU: 20ì´ˆ (40ë°° ì°¨ì´)
```

### Phase 1 ì ìš© í›„
```
GPU (Phase 1): 0.03-0.04ì´ˆ
CPU ëŒ€ë¹„: 500-600ë°° í–¥ìƒ
í˜„ì¬ GPU ëŒ€ë¹„: 12-15ë°° í–¥ìƒ
```

### Phase 2 ì ìš© í›„
```
GPU (Phase 2): 0.003-0.006ì´ˆ
CPU ëŒ€ë¹„: 3,000-6,000ë°° í–¥ìƒ
í˜„ì¬ GPU ëŒ€ë¹„: 80-150ë°° í–¥ìƒ
```

### Phase 3 ì ìš© í›„
```
GPU (Phase 3): 0.003-0.005ì´ˆ
CPU ëŒ€ë¹„: 4,000-6,000ë°° í–¥ìƒ
í˜„ì¬ GPU ëŒ€ë¹„: 100-150ë°° í–¥ìƒ
```

---

## êµ¬í˜„ ìš°ì„ ìˆœìœ„ ì¶”ì²œ

### ì¦‰ì‹œ êµ¬í˜„ (1ì£¼, ë†’ì€ ROI)
1. âœ… **Batched Tridiagonal Solver (cuSPARSE)**
   - ê°€ì¥ í° íš¨ê³¼ (20ë°°)
   - êµ¬í˜„ ê°„ë‹¨
   - ì•ˆì •ì„± ë³´ì¥

2. âœ… **Vectorized ì¡°ê¸°ìƒí™˜ ì²´í¬**
   - ì¤‘ê°„ íš¨ê³¼ (50ë°°, í•˜ì§€ë§Œ ë¹„ì¤‘ 10%)
   - êµ¬í˜„ ë³´í†µ
   - GPUâ†”CPU ì „ì†¡ ì œê±°

### ì„ íƒì  êµ¬í˜„ (2-3ì£¼, ì¤‘ê°„ ROI)
3. âš ï¸ **Custom CUDA Kernel**
   - ì¶”ê°€ íš¨ê³¼ (2-3ë°°)
   - êµ¬í˜„ ë³µì¡
   - ë””ë²„ê¹… ì–´ë ¤ì›€

4. âš ï¸ **Parallel Cyclic Reduction**
   - ì¶”ê°€ íš¨ê³¼ (3-5ë°°)
   - êµ¬í˜„ ë§¤ìš° ë³µì¡
   - ìˆ˜ì¹˜ ì•ˆì •ì„± ì´ìŠˆ

### ë¯¸ì„¸ ì¡°ì • (1ì£¼, ë‚®ì€ ROI)
5. â–³ **Memory Optimization**
   - ë¯¸ë¯¸í•œ íš¨ê³¼ (10-20%)
   - ë³µì¡ë„ ì¦ê°€
   - ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´

---

## ê²°ë¡ 

**í˜„ì¬ GPU êµ¬í˜„:**
- âœ… ë°ì´í„° GPU ì €ì¥
- âœ… ê²½ê³„ì¡°ê±´ GPU ì²˜ë¦¬
- â–³ Thomas ì•Œê³ ë¦¬ì¦˜ GPU ì‹¤í–‰ (ìˆœì°¨ì )
- âŒ Batched solve ë¯¸êµ¬í˜„ (ê°€ì¥ í° ë³‘ëª©)
- âŒ ì¡°ê¸°ìƒí™˜ ì²´í¬ CPU ì‹¤í–‰
- âŒ ë§Œê¸° í˜ì´ì˜¤í”„ CPU ì‹¤í–‰

**ìµœìš°ì„  ê°œì„  ì‚¬í•­:**
1. Batched tridiagonal solver (20ë°° í–¥ìƒ)
2. Vectorized ì¡°ê¸°ìƒí™˜ (ì „ì²´ 10% í–¥ìƒ)

**ì˜ˆìƒ ì´ í–¥ìƒ: 12-15ë°°**
**ìµœì¢… ì†ë„: 0.5s â†’ 0.03-0.04s**

ì´ ì •ë„ë©´ ì‹¤ì‹œê°„ í”„ë¼ì´ì‹±ì— ì¶©ë¶„í•˜ë©°, ë” í° ê·¸ë¦¬ë“œ(200Ã—200)ë„ ë¹ ë¥´ê²Œ ì²˜ë¦¬ ê°€ëŠ¥.
