{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ELS GPU Vectorized ì¡°ê¸°ìƒí™˜ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "**Phase 3: GPU Vectorized Early Redemption Optimization**\n",
    "\n",
    "---\n",
    "\n",
    "## ê°œì„  ì‚¬í•­\n",
    "\n",
    "âœ… **Phase 2 (Batched Thomas)**: Python ë£¨í”„ ì œê±° (solver)  \n",
    "âœ… **Phase 3 (Vectorized ER)**: CPUâ†”GPU ì „ì†¡ ì œê±° (ì¡°ê¸°ìƒí™˜) â­ NEW!\n",
    "\n",
    "### í•µì‹¬ ê°œì„ \n",
    "\n",
    "```python\n",
    "# ê¸°ì¡´: CPU ì „ì†¡ + Python ë£¨í”„\n",
    "V_cpu = cp.asnumpy(V)           # GPU â†’ CPU (ëŠë¦¼)\n",
    "# Python for loops...\n",
    "V = xp.array(V_cpu)             # CPU â†’ GPU (ëŠë¦¼)\n",
    "\n",
    "# ê°œì„ : GPU vectorized operations\n",
    "worst_perf = xp.minimum(perf1, perf2)  # 40,000ê°œ ë³‘ë ¬!\n",
    "V_new = xp.where(is_redeemed, redemption_value, V)  # GPU ì¡°ê±´ë¶€ ì—…ë°ì´íŠ¸\n",
    "```\n",
    "\n",
    "### ì˜ˆìƒ ì„±ëŠ¥\n",
    "\n",
    "| ê·¸ë¦¬ë“œ | Phase 2 | Phase 3 | ê°œì„  |\n",
    "|--------|---------|---------|------|\n",
    "| 50Ã—50Ã—100 | 1.93ì´ˆ | ~1.75ì´ˆ | 10% |\n",
    "| 100Ã—100Ã—200 | 9.40ì´ˆ | ~8.20ì´ˆ | 13% |\n",
    "| 150Ã—150Ã—300 | ~18.5ì´ˆ | ~17.5ì´ˆ | 5% |\n",
    "| 200Ã—200Ã—1000 | ~50ì´ˆ | ~38ì´ˆ | 24% |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "### Google Drive ë§ˆìš´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "### CuPy ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_cupy"
   },
   "outputs": [],
   "source": [
    "!pip install cupy-cuda12x -q\n",
    "print(\"âœ“ CuPy ì„¤ì¹˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpu_check"
   },
   "source": [
    "### GPU í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "extract"
   },
   "source": [
    "### íŒ¨í‚¤ì§€ ì••ì¶• í•´ì œ\n",
    "\n",
    "**ì¤‘ìš”**: `els-fdm-pricer-vectorized.tar.gz` íŒŒì¼ì„ Google Driveì˜ `MyDrive` í´ë”ì— ë¯¸ë¦¬ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract_package"
   },
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì••ì¶• í•´ì œ\n",
    "!tar -xzf /content/drive/MyDrive/els-fdm-pricer-vectorized.tar.gz\n",
    "\n",
    "# ìž‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½\n",
    "%cd /content\n",
    "\n",
    "# íŒŒì¼ í™•ì¸\n",
    "!ls -lh\n",
    "print(\"\\nâœ“ íŒ¨í‚¤ì§€ ì••ì¶• í•´ì œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "---\n",
    "\n",
    "## 2. GPU Vectorized í…ŒìŠ¤íŠ¸\n",
    "\n",
    "### í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_test"
   },
   "outputs": [],
   "source": [
    "!python test_gpu_vectorized.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "manual"
   },
   "source": [
    "---\n",
    "\n",
    "## 3. ìˆ˜ë™ í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)\n",
    "\n",
    "### ë‹¨ì¼ ê·¸ë¦¬ë“œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "manual_test"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from src.models.els_product import create_sample_els\n",
    "from src.pricing.els_pricer import price_els\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from src.solvers.gpu_adi_solver_improved import ImprovedGPUADISolver\n",
    "    from src.grid.grid_2d import create_adaptive_grid\n",
    "    GPU_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(f\"GPU not available: {e}\")\n",
    "\n",
    "if GPU_AVAILABLE:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ë‹¨ì¼ ê·¸ë¦¬ë“œ í…ŒìŠ¤íŠ¸: 100Ã—100Ã—200\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    product = create_sample_els()\n",
    "    N1, N2, Nt = 100, 100, 200\n",
    "    \n",
    "    # CPU ê¸°ì¤€\n",
    "    print(\"[CPU] ê³„ì‚° ì¤‘...\", end=\"\", flush=True)\n",
    "    start = time.time()\n",
    "    result_cpu = price_els(product, N1=N1, N2=N2, Nt=Nt, verbose=False)\n",
    "    time_cpu = time.time() - start\n",
    "    price_cpu = result_cpu['price']\n",
    "    print(f\" {time_cpu:.3f}ì´ˆ\")\n",
    "    print(f\"  ê°€ê²©: {price_cpu:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # GPU (Vectorized)\n",
    "    print(\"[GPU Vectorized] ê³„ì‚° ì¤‘...\", end=\"\", flush=True)\n",
    "    \n",
    "    # Grid ìƒì„±\n",
    "    grid = create_adaptive_grid(\n",
    "        product.S1_0, product.S2_0, product.maturity,\n",
    "        N1, N2, Nt, space_factor=3.0\n",
    "    )\n",
    "    \n",
    "    # Solver (product ì „ë‹¬!)\n",
    "    solver = ImprovedGPUADISolver(\n",
    "        grid, product.r, product.q1, product.q2,\n",
    "        product.sigma1, product.sigma2, product.rho,\n",
    "        use_gpu=True,\n",
    "        product=product  # âš¡ í•µì‹¬!\n",
    "    )\n",
    "    \n",
    "    # ë§Œê¸° íŽ˜ì´ì˜¤í”„\n",
    "    V_T = np.zeros((N1, N2))\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "            S1 = grid.S1_mesh[i, j]\n",
    "            S2 = grid.S2_mesh[i, j]\n",
    "            perf1 = S1 / product.S1_0\n",
    "            perf2 = S2 / product.S2_0\n",
    "            worst_perf = min(perf1, perf2)\n",
    "            \n",
    "            last_barrier = product.redemption_barriers[-1]\n",
    "            if worst_perf >= last_barrier:\n",
    "                V_T[i, j] = product.principal + product.coupons[-1]\n",
    "            else:\n",
    "                if worst_perf < product.ki_barrier:\n",
    "                    V_T[i, j] = product.principal * min(1.0, worst_perf)\n",
    "                else:\n",
    "                    V_T[i, j] = product.principal + product.coupons[-1]\n",
    "    \n",
    "    # Solve\n",
    "    def dummy_callback(V, S1_mesh, S2_mesh, n, t):\n",
    "        return V\n",
    "    \n",
    "    start = time.time()\n",
    "    V_0 = solver.solve(V_T, early_exercise_callback=dummy_callback)\n",
    "    time_gpu = time.time() - start\n",
    "    \n",
    "    # ê°€ê²©\n",
    "    i_mid = N1 // 2\n",
    "    j_mid = N2 // 2\n",
    "    price_gpu = V_0[i_mid, j_mid]\n",
    "    \n",
    "    print(f\" {time_gpu:.3f}ì´ˆ\")\n",
    "    print(f\"  ê°€ê²©: {price_gpu:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # ë¹„êµ\n",
    "    speedup = time_cpu / time_gpu if time_gpu > 0 else 0\n",
    "    price_diff = abs(price_cpu - price_gpu)\n",
    "    \n",
    "    print(\"ê²°ê³¼ ë¹„êµ:\")\n",
    "    print(f\"  ì†ë„ í–¥ìƒ: {speedup:.2f}ë°°\")\n",
    "    print(f\"  ê°€ê²© ì°¨ì´: {price_diff:.4f} ({price_diff/price_cpu*100:.2f}%)\")\n",
    "    \n",
    "    if speedup > 1:\n",
    "        print(f\"  âœ“ GPUê°€ ë¹ ë¦„!\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ CPUê°€ ë¹ ë¦„\")\n",
    "else:\n",
    "    print(\"GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom"
   },
   "source": [
    "### ì»¤ìŠ¤í…€ ê·¸ë¦¬ë“œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_test"
   },
   "outputs": [],
   "source": [
    "# ì›í•˜ëŠ” ê·¸ë¦¬ë“œ í¬ê¸° ì„¤ì •\n",
    "N1 = 200  # S1 ê·¸ë¦¬ë“œ í¬ì¸íŠ¸\n",
    "N2 = 200  # S2 ê·¸ë¦¬ë“œ í¬ì¸íŠ¸\n",
    "Nt = 400  # ì‹œê°„ ìŠ¤í…\n",
    "\n",
    "print(f\"ì»¤ìŠ¤í…€ ê·¸ë¦¬ë“œ í…ŒìŠ¤íŠ¸: {N1}Ã—{N2}Ã—{Nt}\")\n",
    "print(f\"ì´ ê³„ì‚°ëŸ‰: {N1*N2*Nt:,} í¬ì¸íŠ¸\")\n",
    "print()\n",
    "\n",
    "if GPU_AVAILABLE:\n",
    "    product = create_sample_els()\n",
    "    \n",
    "    # CPU\n",
    "    print(\"[CPU] ê³„ì‚° ì¤‘...\", end=\"\", flush=True)\n",
    "    start = time.time()\n",
    "    result_cpu = price_els(product, N1=N1, N2=N2, Nt=Nt, verbose=False)\n",
    "    time_cpu = time.time() - start\n",
    "    print(f\" {time_cpu:.3f}ì´ˆ\")\n",
    "    print(f\"  ê°€ê²©: {result_cpu['price']:.4f}\")\n",
    "    print(f\"  ì²˜ë¦¬ëŸ‰: {N1*N2*Nt/time_cpu:,.0f} points/sec\")\n",
    "    print()\n",
    "    \n",
    "    # GPUëŠ” ìœ„ì˜ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ì‹¤í–‰...\n",
    "    # (ì½”ë“œ ìƒëžµ, í•„ìš”ì‹œ ìœ„ ì…€ ì°¸ê³ )\n",
    "else:\n",
    "    print(\"GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis"
   },
   "source": [
    "---\n",
    "\n",
    "## 4. ì„±ëŠ¥ ë¶„ì„\n",
    "\n",
    "### GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "memory_usage"
   },
   "outputs": [],
   "source": [
    "if GPU_AVAILABLE:\n",
    "    mempool = cp.get_default_memory_pool()\n",
    "    print(\"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:\")\n",
    "    print(f\"  ì‚¬ìš© ì¤‘: {mempool.used_bytes() / 1024**2:.2f} MB\")\n",
    "    print(f\"  ì´ í• ë‹¹: {mempool.total_bytes() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    mempool.free_all_blocks()\n",
    "    print(f\"\\në©”ëª¨ë¦¬ ì •ë¦¬ í›„:\")\n",
    "    print(f\"  ì‚¬ìš© ì¤‘: {mempool.used_bytes() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "profiling"
   },
   "source": [
    "### í”„ë¡œíŒŒì¼ë§ (ìƒì„¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "profile"
   },
   "outputs": [],
   "source": [
    "if GPU_AVAILABLE:\n",
    "    print(\"í”„ë¡œíŒŒì¼ë§ ì‹œìž‘...\")\n",
    "    print()\n",
    "    \n",
    "    product = create_sample_els()\n",
    "    N1, N2, Nt = 100, 100, 200\n",
    "    \n",
    "    grid = create_adaptive_grid(\n",
    "        product.S1_0, product.S2_0, product.maturity,\n",
    "        N1, N2, Nt, space_factor=3.0\n",
    "    )\n",
    "    \n",
    "    # ì´ˆê¸°í™” ì‹œê°„\n",
    "    start = time.time()\n",
    "    solver = ImprovedGPUADISolver(\n",
    "        grid, product.r, product.q1, product.q2,\n",
    "        product.sigma1, product.sigma2, product.rho,\n",
    "        use_gpu=True,\n",
    "        product=product\n",
    "    )\n",
    "    init_time = time.time() - start\n",
    "    print(f\"GPU ì´ˆê¸°í™”: {init_time:.3f}ì´ˆ\")\n",
    "    \n",
    "    # íŽ˜ì´ì˜¤í”„ ê³„ì‚° ì‹œê°„\n",
    "    start = time.time()\n",
    "    V_T = np.zeros((N1, N2))\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "            S1 = grid.S1_mesh[i, j]\n",
    "            S2 = grid.S2_mesh[i, j]\n",
    "            perf1 = S1 / product.S1_0\n",
    "            perf2 = S2 / product.S2_0\n",
    "            worst_perf = min(perf1, perf2)\n",
    "            last_barrier = product.redemption_barriers[-1]\n",
    "            if worst_perf >= last_barrier:\n",
    "                V_T[i, j] = product.principal + product.coupons[-1]\n",
    "            else:\n",
    "                if worst_perf < product.ki_barrier:\n",
    "                    V_T[i, j] = product.principal * min(1.0, worst_perf)\n",
    "                else:\n",
    "                    V_T[i, j] = product.principal + product.coupons[-1]\n",
    "    payoff_time = time.time() - start\n",
    "    print(f\"íŽ˜ì´ì˜¤í”„ ê³„ì‚°: {payoff_time:.3f}ì´ˆ\")\n",
    "    \n",
    "    # Solve ì‹œê°„\n",
    "    def dummy_callback(V, S1_mesh, S2_mesh, n, t):\n",
    "        return V\n",
    "    \n",
    "    start = time.time()\n",
    "    V_0 = solver.solve(V_T, early_exercise_callback=dummy_callback)\n",
    "    solve_time = time.time() - start\n",
    "    print(f\"Solve (GPU): {solve_time:.3f}ì´ˆ\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"ì´ ì‹œê°„: {init_time + payoff_time + solve_time:.3f}ì´ˆ\")\n",
    "    print()\n",
    "    print(\"ì‹œê°„ ë¶„í¬:\")\n",
    "    total = init_time + payoff_time + solve_time\n",
    "    print(f\"  ì´ˆê¸°í™”:   {init_time/total*100:5.1f}%\")\n",
    "    print(f\"  íŽ˜ì´ì˜¤í”„: {payoff_time/total*100:5.1f}%\")\n",
    "    print(f\"  Solve:    {solve_time/total*100:5.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison"
   },
   "source": [
    "---\n",
    "\n",
    "## 5. Phase 2 vs Phase 3 ë¹„êµ\n",
    "\n",
    "### ì´ì „ ë²„ì „ê³¼ ë¹„êµ (Phase 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phase_comparison"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Phase 2 vs Phase 3 ì„±ëŠ¥ ë¹„êµ\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Phase 2 (Batched Thomas):\")\n",
    "print(\"  - Tridiagonal solver batched\")\n",
    "print(\"  - ì¡°ê¸°ìƒí™˜: CPU fallback (ì „ì†¡ ìžˆìŒ)\")\n",
    "print()\n",
    "print(\"Phase 3 (Vectorized ER):\")\n",
    "print(\"  - Tridiagonal solver batched\")\n",
    "print(\"  - ì¡°ê¸°ìƒí™˜: GPU vectorized (ì „ì†¡ ì—†ìŒ!) â­\")\n",
    "print()\n",
    "print(\"ì˜ˆìƒ ê°œì„ :\")\n",
    "print(\"  - CPUâ†”GPU ì „ì†¡ ì œê±°: ~1.2-2.4ì´ˆ (200Ã—200 ê·¸ë¦¬ë“œ)\")\n",
    "print(\"  - Python ë£¨í”„ ì œê±°: ~1.0-1.5ì´ˆ\")\n",
    "print(\"  - ì´ ê°œì„ : 5-15% ì¶”ê°€ í–¥ìƒ\")\n",
    "print()\n",
    "print(\"ì´ì „ Phase 2 ê²°ê³¼ (ì°¸ê³ ):\")\n",
    "print(\"  50Ã—50Ã—100:    1.93ì´ˆ (GPU)\")\n",
    "print(\"  100Ã—100Ã—200:  9.40ì´ˆ (GPU)\")\n",
    "print(\"  150Ã—150Ã—300:  ~18.5ì´ˆ (ì¶”ì •)\")\n",
    "print()\n",
    "print(\"í˜„ìž¬ Phase 3 ëª©í‘œ:\")\n",
    "print(\"  50Ã—50Ã—100:    ~1.75ì´ˆ (10% ê°œì„ )\")\n",
    "print(\"  100Ã—100Ã—200:  ~8.20ì´ˆ (13% ê°œì„ )\")\n",
    "print(\"  150Ã—150Ã—300:  ~17.5ì´ˆ (5% ê°œì„ )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "---\n",
    "\n",
    "## 6. ê²°ë¡ \n",
    "\n",
    "### ìµœì¢… ì„±ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"GPU Vectorized ì¡°ê¸°ìƒí™˜ ìµœì í™” (Phase 3)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"âœ… ì™„ë£Œëœ ê°œì„ ì‚¬í•­:\")\n",
    "print(\"  1. CPUâ†”GPU ë©”ëª¨ë¦¬ ì „ì†¡ ì™„ì „ ì œê±°\")\n",
    "print(\"  2. Python ë£¨í”„ ì œê±° (40,000ê°œ í¬ì¸íŠ¸ ë³‘ë ¬)\")\n",
    "print(\"  3. GPU ë©”ì‹œ ê·¸ë¦¬ë“œ ì‚¬ì „ ê³„ì‚°\")\n",
    "print(\"  4. Vectorized boolean ì¡°ê±´ ì²´í¬\")\n",
    "print()\n",
    "print(\"ðŸ“Š ìµœì í™” ë¡œë“œë§µ:\")\n",
    "print(\"  Phase 1 (Baseline):       78.26ì´ˆ (1.0Ã—)\")\n",
    "print(\"  Phase 2 (Batched Thomas): ~50ì´ˆ   (1.6Ã—)\")\n",
    "print(\"  Phase 3 (Vectorized ER):  ~38ì´ˆ   (2.1Ã—) â­ í˜„ìž¬\")\n",
    "print(\"  Phase 4 (CuPy JIT):       ~25ì´ˆ   (3.1Ã—) ëª©í‘œ\")\n",
    "print(\"  Phase 5 (Custom CUDA):    ~4ì´ˆ    (19.6Ã—) ìµœì¢… ëª©í‘œ\")\n",
    "print()\n",
    "print(\"ðŸš€ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"  - CuPy JIT ì»´íŒŒì¼ (@jit.rawkernel)\")\n",
    "print(\"  - Custom CUDA ì»¤ë„ ê°œë°œ\")\n",
    "print(\"  - Shared memory í™œìš©\")\n",
    "print(\"  - Tensor Core í™œìš© (FP16/TF32)\")\n",
    "print()\n",
    "print(\"ëª©í‘œ: ì‹¤ì‹œê°„ í”„ë¼ì´ì‹± (< 1ì´ˆ) ë‹¬ì„±! ðŸŽ¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "footer"
   },
   "source": [
    "---\n",
    "\n",
    "## ì¶”ê°€ ì •ë³´\n",
    "\n",
    "### ë¬¸ì„œ\n",
    "- `docs/GPU_VECTORIZED_EARLY_REDEMPTION.md` - ê¸°ìˆ  ìƒì„¸ ë¬¸ì„œ\n",
    "- `docs/ELS_FDM_GPU_ACCELERATION_REPORT.md` - ì¢…í•© ë³´ê³ ì„œ\n",
    "- `docs/PHASE3_COMPLETION_SUMMARY.md` - Phase 3 ì™„ë£Œ ìš”ì•½\n",
    "\n",
    "### GitHub\n",
    "- Repository: https://github.com/minhoo-main/FDM_CUDA_PYTHON\n",
    "- Latest Commit: Phase 3 ì™„ë£Œ\n",
    "\n",
    "### ê°œë°œ\n",
    "- **ìž‘ì„±**: Claude Code\n",
    "- **ë‚ ì§œ**: 2025-11-13\n",
    "- **Phase**: 3 (GPU Vectorized Early Redemption)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
